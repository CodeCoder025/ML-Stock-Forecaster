#Hyperparameter optimization
import matplotlib.pyplot as plt
import numpy as np
import time
import random

startTime = time.time()
def optimizeRF(dataset1,batchRun = False, batchNumber = None):
    trainData, testData = dataset1
    if batchRun == False:
      # 442 750 iterations
      n_estimatorList = list(range(5, 120, 1))
      max_samplesList = np.arange(0.05, 0.6, 0.01) #gotta do this because range() cannot take floats
      max_leaf_nodeList = list(range(100, 450,5))
    elif batchRun == True:
      # 15 600 iterations
      n_estimatorList = list(range(40, 120, 2))
      max_samplesList = np.arange(0.3, 0.95, 0.05)
      max_leaf_nodeList = list(range(200, 350,5))
    n_estimatorsHPlist = []
    max_samplesHPlist = []
    max_leaf_nodesHPlist = []
    RMSElist = []
    x = 0
    for i in range(len(n_estimatorList)):
        for j in range(len(max_samplesList)):
            for k in range(len(max_leaf_nodeList)):
                n_estimatorsHPlist.append(n_estimatorList[i])
                max_samplesHPlist.append(max_samplesList[j])
                max_leaf_nodesHPlist.append(max_leaf_nodeList[k])
                _,_,randomForestScore = deployRandomForest(trainData, testData,
                                                           n_dTrees = n_estimatorList[i],
                                                           bootstrapSize = max_samplesList[j],
                                                           max_leaf_nodes = max_leaf_nodeList[k])
                RMSElist.append(randomForestScore)
                x+=1
                if batchRun == False:
                  print("Progress: %s/%s"%(x, len(n_estimatorList)*len(max_samplesList)*len(max_leaf_nodeList)))
                else:
                  print("Progress: %s/%s  <-----   Batch Number: %s"%(x, len(n_estimatorList)*len(max_samplesList)*len(max_leaf_nodeList), batchNumber))
    bestCombiIndex = RMSElist.index(min(RMSElist))
    fig = plt.figure() #How to make 4-metric plots --- https://chatgpt.com/s/t_6953e151d9988191b7bc7da461e03aa0
    ax = fig.add_subplot(projection = "3d")
    scatPlot = ax.scatter(n_estimatorsHPlist, max_leaf_nodesHPlist, RMSElist,c=max_samplesHPlist, cmap = "viridis")
    ax.scatter(n_estimatorsHPlist[bestCombiIndex],max_leaf_nodesHPlist[bestCombiIndex],RMSElist[bestCombiIndex], s=80, marker = "X", label = "OPtimum")
    ax.set_xlabel("n_estimators")
    ax.set_ylabel("Maximum Terminal Nodes")
    ax.set_zlabel("RMSE")
    plt.colorbar(scatPlot, label = "Bootstrap Size")
    plt.show()
    return {"Max Samples" : max_samplesHPlist[bestCombiIndex],"Max Terminal Nodes":max_leaf_nodesHPlist[bestCombiIndex],"n_estimators":n_estimatorsHPlist[bestCombiIndex],"RMSE Score":RMSElist[bestCombiIndex]}

def batchOptimization(dataset1, batchesToDo, colBatchSize = "root"):
  trainData, testData = dataset1
  if colBatchSize == "root":
    colBatchSize = int((len(trainData.columns.to_list()))**0.5)
  dataDict = {}
  for j in range(batchesToDo):
    batchedTrain = pd.DataFrame()
    batchedTest = pd.DataFrame()
    columnsToUse = random.sample(range(0,len(trainData.columns.to_list())), k = colBatchSize)
    targetColumnIndex = trainData.columns.get_loc("%changeTomorrow")
    if (targetColumnIndex in columnsToUse) == False:
      columnsToUse.append(targetColumnIndex)
    columnsToUseString = ""
    for i in columnsToUse:
      batchedTrain[trainData.columns.to_list()[i]] = trainData[trainData.columns.to_list()[i]]
      batchedTest[trainData.columns.to_list()[i]] = testData[trainData.columns.to_list()[i]]
      columnsToUseString += "%s*"%str(i)
    batchedDataset = [batchedTrain, batchedTest]
    batchData = optimizeRF(batchedDataset, batchRun = True, batchNumber = j)
    batchData = batchData.values() #Order of values in batchdata ---> Max Samples, Max Terminal Nodes, n_estimators, RMSE Score 
    dataDict[columnsToUseString] = batchData
  bestScoreIndex = None
  iterationCounter = -1 #Zero-based indexing
  bestRMSE = 0
  for columnsUsed, outputResult in dataDict.items():
    iterationCounter+=1
    if bestRMSE == 0 or bestRMSE >= outputResult[-1]:
      bestRMSE = outputResult[-1]
      bestRMSEstat = [i for i in outputResult if i != outputResult[-1]]
      RMSEbatchData = columnsToUseString.split("*")
    else:
      pass
  return bestRMSE, bestRMSEstat, RMSEbatchData

bestRMSE, bestRMSEstat, bestRMSEcolumnsList = batchOptimization(dataset1, 30, colBatchSize = "root")
timeDiff = float(time.time()) - startTime
print(bestRMSE)
print(bestRMSEstat)
print(bestRMSEcolumnsList)
print("Time Taken for Optimization:        %s Seconds" %timeDiff)
